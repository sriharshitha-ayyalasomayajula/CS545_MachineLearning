{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d713a85d",
   "metadata": {},
   "source": [
    "Experiment 1: Vary the number of hidden inputs \n",
    "where n = 20,50,100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12e4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import math \n",
    "import numpy as np \n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import random \n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a3fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training data\n",
    "file_train = (\"mnist_train.csv\",\"r\")\n",
    "train_data = csv.reader(file_train)\n",
    "train = np.array(list(train_data))\n",
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9c5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test data\n",
    "file_test = (\"mnist_test.csv\",\"r\")\n",
    "test_data = csv.reader(file_test)\n",
    "test = np.array(list(test_data))\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30ad319",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train)\n",
    "train = train[0:60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8362aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the values of bias,learning rate and momentum\n",
    "bias = 1\n",
    "learning_rate = 0.1\n",
    "m = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b6669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To vary the hidden inputs, change the n value to 50 and 100 \n",
    "#Number of hidden inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a861c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appling the weights\n",
    "\n",
    "#weights from inner layer to hidden layer\n",
    "weight_ih = np.random.uniform(-0.05,0.05,(785,n))\n",
    "#print(weight_ih.shape)\n",
    "\n",
    "#weight from hidden layer to outer layer\n",
    "weight_ho = np.random.uniform(-0.05,0.05,(n+1,10))\n",
    "#print(weight_ho.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eb18417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the delta weight from hidden layer to output layer\n",
    "previous_weight_ho = np.zeros((n+1,10))\n",
    "\n",
    "#Store the delta weight from the input to the hidden layer\n",
    "previous_weight_ih = np.zeros((785,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b117c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A matrix to store the activation h1...hk\n",
    "h1_input = np.zeros((1,n+1))\n",
    "h1_input[0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80d5e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Perceptron\n",
    "def multi_perceptron(epoch,input_ds,set_flag):\n",
    "    global weight_ih, weight_ho, previous_weight_ih, previous_weight_ho\n",
    "    predict_list =[]\n",
    "    actual_list = []\n",
    "    for i in range(input_ds.shape[0]):\n",
    "        target_class = input_ds[i,0].astype('int')\n",
    "        actual_list.append(target_class)\n",
    "        xi = input_ds[i].astype('float16')/255\n",
    "        xi[0] = bias\n",
    "        xi = xi.reshape(1,785)\n",
    "        \n",
    "        z_h1 = np.dot(xi,weight_ih)\n",
    "        sigmoid_h1 = expit(z_h1)\n",
    "        print(\"sigmoid_h1\",sigmoid_h1.shape)\n",
    "        \n",
    "        h1_input[0,1:] = sigmoid_h1\n",
    "        print(\"h1 input\",h1_input)\n",
    "        print(h1_input.shape)\n",
    "        z_o1 = np.dot(h1_input,weight_ho)\n",
    "        sigmoid_o1 = expit(z_o1)\n",
    "        print(\"sigmoid_o1\",sigmoid_o1)\n",
    "        \n",
    "        predict = np.argmax(sigmoid_o1)\n",
    "        print(predict)\n",
    "        predict_list.append(predict)\n",
    "        print(type(sigmoid_o1))\n",
    "        print(sigmoid_o1.shape)\n",
    "        \n",
    "        if epoch>0 and set_flag == 1:\n",
    "            #print error for output unit\n",
    "            tk = np.zeros((1,10))+0.1\n",
    "            tk[0,target_class] = 0.9\n",
    "            print(tk)\n",
    "            error_o1 = sigmoid_o1 * (1 - sigmoid_o1) * (tk - sigmoid_o1) \n",
    "            print(\"error_o1 shape for \",epoch,\" \", error_o1.shape)\n",
    "            \n",
    "            #print error for hidden unit\n",
    "            error_h1 = sigmoid_h1 * (1 - sigmoid_h1) * np.dot(error_o1,weight_ho[1:,:].T)\n",
    "            print(\"error_h1 shape for \",epoch,\" \",error_h1.shape)\n",
    "            \n",
    "            #Update the weights of hidden layer to outer layer\n",
    "            \n",
    "            delta_weight_ho = (learning_rate * error_o1 * h1_input.T) + (m * previous_weight_ho)\n",
    "            previous_weight_ho = delta_weight_ho\n",
    "            print(delta_weight_ho.shape)\n",
    "            weight_ho = weight_ho + delta_weight_ho\n",
    "            \n",
    "            #Updating the weights of input to output\n",
    "            \n",
    "            delta_weight_ih = (learning_rate * error_h1 * x.T) + (m * previous_weight_ih)\n",
    "            previous_weight_ih = delta_weight_ih\n",
    "            print(delta_weight_ih.shape)\n",
    "            weight_ih = weight_ih + delta_weight_ih\n",
    "            \n",
    "        accuracy = (np.array(predict_list) == np.array(actual_list)).sum()/float(len(actual_list)) * 100\n",
    "        print(\"Length of actual list after \",epoch,\" : \",len(actual_list))\n",
    "        print(\"Length of prediction  list after \",epoch,\" : \",len(predict_list))\n",
    "        \n",
    "        if (set_flag == 0):\n",
    "            print(\"Confusion Matrix for epoch\",epoch)\n",
    "            print(confusion_matrix(actual_list,predict_list))\n",
    "            \n",
    "        return accuracy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "801137d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_accuracy(accuracy_index,accuracy,input_ds):\n",
    "    with open(input_ds, 'a', newline = '') as myfile:\n",
    "        wr = csv.writer(myfile)\n",
    "        wr.writerow([accuracy_index,accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eaf69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in range(50):\n",
    "    train_accuarcy = multi_perceptron(each,train,1)\n",
    "    test_accuracy = multi_perceptron(each,test,0)\n",
    "    store_accuracy(each,train_accuracy,'train_no='+str(m)+'.csv')\n",
    "    store_accuracy(each,test_accuracy,'test_no='+str(m)+'.csv')          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc41690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the graph\n",
    "x1,y1 = np.loadtxt(\"train_no.csv\",delimiter=',',unpack=True)\n",
    "x2,y2 = np.loadtxt(\"test_no.csv\",delimiter=',',unpack=True)\n",
    "plt.plot(x1,y1,label=\"Training Set\")\n",
    "plt.plot(x2,y2,label=\"Test Set\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title ('Experiment 1 For n=20')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
