{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83edda3",
   "metadata": {},
   "source": [
    "Experiment 3: Vary the number of trainning examples\n",
    "    training exampless = 15000 , 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "626262d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9179f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_file = open(\"mnist_train.csv\",\"r\")\n",
    "train_data = csv.reader(train_file)\n",
    "train = np.array(list(train_data))\n",
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "test_file = open(\"mnist_test.csv\",\"r\")\n",
    "test_data = csv.reader(test_file)\n",
    "test = np.array(list(test_data))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10092091",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train)\n",
    "#The tarining examples vary, so consider 15000, 30000\n",
    "train = train[0:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee0d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the values of bias, learning rate and momentum\n",
    "bias = 1\n",
    "learning_rate = 0.1\n",
    "m = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe799eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hidden inputs\n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d1e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the weights\n",
    "weight_ih = np.random.uniform(-0.05,0.05,(785,n))\n",
    "#print(weight_ih.shape)\n",
    "weight_h0 = np.random.uniform(-0.05,0.05,(n+1,10)) \n",
    "#print(weight_h0.shape)\n",
    "\n",
    "# store previous delta weight from hidden to output layer\n",
    "previous_weight_h0 = np.zeros((n+1,10))\n",
    "# store previous delta weight from input to hidden layer\n",
    "previous_weight_ih = np.zeros((785,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31176d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix to store the activation h1...hk\n",
    "hl_input = np.zeros((1,n+1))\n",
    "hl_input[0,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a66af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the perceptron\n",
    "def multi_perceptron(epoch,input_ds,set_flag):\n",
    "    global weight_ih,weight_h0,previous_weight_ih,previous_weight_h0 \n",
    "    predict_list = []\n",
    "    actual_list = []\n",
    "    for i in range(input_ds.shape[0]):\n",
    "        target_class = input_ds[i,0].astype('int')\n",
    "        actual_list.append(target_class)\n",
    "        xi = input_ds[i].astype('float16')/255\n",
    "        xi[0] = bias\n",
    "        xi = xi.reshape(1,785)\n",
    "        z_hl = np.dot(xi,weight_ih) \n",
    "        sig_hl = expit(z_hl)\n",
    "        # print(hl_input.shape)\n",
    "        z_ol = np.dot(hl_input,weight_h0) \n",
    "        sig_ol = expit(z_ol)\n",
    "        # print(sig_ol)\n",
    "        predict = np.argmax(sig_ol)\n",
    "        # print(sig_ol.shape)\n",
    "        if epoch>0 and set_flag == 1:\n",
    "            ##error term for output unit\n",
    "            tk = np.zeros((1,10))+0.1\n",
    "            tk[0,target_class] = 0.9\n",
    "            # print(tk)\n",
    "            error_ol = sig_ol*(1-sig_ol)* (tk - sig_ol)\n",
    "            # print(\"error_ol shape for \",epoch,\" \",error_ol.shape)\n",
    "            \n",
    "            #error term for hidden unit\n",
    "            error_hl = sig_hl*(1-sig_hl)* np.dot (error_ol,weight_h0[1:,:].T) \n",
    "            # print(\"error_hl shape for \",epoch,\" \",error_hl.shape)\n",
    "            \n",
    "            # Update the weights #\n",
    "            delta_weight_h0 = (learning_rate * error_ol * hl_input.T) + (m * previous_weight_h0) \n",
    "            previous_weight_h0 = delta_weight_h0\n",
    "            weight_h0 = weight_h0 + delta_weight_h0\n",
    "            \n",
    "            ### Input to output layer wt updation\n",
    "            delta_weight_ih = (learning_rate * error_hl * xi.T) + (m * previous_weight_ih) \n",
    "            previous_weight_ih = delta_weight_ih\n",
    "            weight_ih = weight_ih + delta_weight_ih\n",
    "\n",
    "    accur = (np.array(predict_list) == np.array(actual_list)).sum()\n",
    "    accuracy = accur_sum/float(len(actual_list))*100\n",
    "    print(\"len of actual_list after \", epoch,\" is \",len(actual_list))\n",
    "    print(\"len of predict_list after \", epoch,\" is \",len(predict_list))\n",
    "    \n",
    "    if(set_flag == 0):\n",
    "        print(\"Confusion matrix for epoch \",epoch)  \n",
    "        print(confusion_matrix(actual_list,predict_list))\n",
    "    return accuracy      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc6abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_accuracy(accuract_index,accuracy,input_ds):\n",
    "     with open(input_ds, 'a', newline='') as myfile:\n",
    "        wr = csv.writer(myfile)\n",
    "        wr.writerow([accuracy_index,accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in range(50):\n",
    "    train_accuracy = multi_perceptron(each,train,1)\n",
    "    test_accuracy = multi_perceptron(each,test,0)\n",
    "    store_accuracy(each,train_accuracy,'train_quarter'+str(m)+'.csv') \n",
    "    store_accuracy(each,test_accuracy,'test_quarter'+str(m)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the graph\n",
    "x1, y1 = np.loadtxt(\"train_quarter.csv\",delimiter=',',unpack=True) \n",
    "x2, y2 = np.loadtxt(\"test_quarter.csv\",delimiter=',',unpack=True) \n",
    "plt.plot(x1,y1, label=\"Training Set\")\n",
    "plt.plot(x2,y2, label=\"Test Set\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%) ')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
